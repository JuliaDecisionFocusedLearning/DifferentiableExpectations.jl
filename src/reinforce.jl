"""
    Reinforce{threaded} <: DifferentiableExpectation{threaded}

Differentiable parametric expectation `F : Î¸ -> ğ”¼[f(X)]` where `X âˆ¼ p(Î¸)` using the REINFORCE (or score function) gradient estimator:
```
âˆ‚F(Î¸) = ğ”¼[f(X) âˆ‡â‚‚logp(X,Î¸)áµ€]
```

# Example

```jldoctest
using DifferentiableExpectations, Distributions, Zygote

F = Reinforce(exp, Normal; nb_samples=10^5)
F_true(Î¼, Ïƒ) = mean(LogNormal(Î¼, Ïƒ))

Î¼, Ïƒ = 0.5, 1,0
âˆ‡F, âˆ‡F_true = gradient(F, Î¼, Ïƒ), gradient(F_true, Î¼, Ïƒ)
isapprox(collect(âˆ‡F), collect(âˆ‡F_true); rtol=1e-1)

# output

true
```

# Constructor

    Reinforce(
        f,
        dist_constructor,
        dist_logdensity_grad=nothing;
        rng=Random.default_rng(),
        nb_samples=1,
        threaded=false,
        seed=nothing
    )

# Fields

$(TYPEDFIELDS)

# See also

- [`DifferentiableExpectation`](@ref)
"""
struct Reinforce{threaded,variance_reduction,F,D,G,R<:AbstractRNG,S<:Union{Int,Nothing}} <:
       DifferentiableExpectation{threaded}
    "function applied inside the expectation"
    f::F
    "constructor of the probability distribution `(Î¸...) -> p(Î¸)`"
    dist_constructor::D
    "either `nothing` or a parameter gradient callable `(x, Î¸...) -> âˆ‡â‚‚logp(x, Î¸)`"
    dist_logdensity_grad::G
    "random number generator"
    rng::R
    "number of Monte-Carlo samples"
    nb_samples::Int
    "seed for the random number generator, reset before each call. Set to `nothing` for no seeding."
    seed::S
end

function Reinforce(
    f::F,
    dist_constructor::D,
    dist_logdensity_grad::G=nothing;
    rng::R=default_rng(),
    nb_samples=1,
    threaded=false,
    variance_reduction=true,
    seed::S=nothing,
) where {F,D,G,R,S}
    return Reinforce{threaded,variance_reduction,F,D,G,R,S}(
        f, dist_constructor, dist_logdensity_grad, rng, nb_samples, seed
    )
end

function dist_logdensity_grad(
    rc::RuleConfig, F::Reinforce{threaded}, x, Î¸...
) where {threaded}
    (; dist_constructor, dist_logdensity_grad) = F
    if !isnothing(dist_logdensity_grad)
        dÎ¸ = dist_logdensity_grad(x, Î¸...)
    else
        _logdensity_partial(_Î¸...) = logdensityof(dist_constructor(_Î¸...), x)
        l, pullback = rrule_via_ad(rc, _logdensity_partial, Î¸...)
        dÎ¸ = Base.tail(pullback(one(l)))
    end
    return dÎ¸
end

function ChainRulesCore.rrule(
    rc::RuleConfig, F::Reinforce{threaded,variance_reduction}, Î¸...; kwargs...
) where {threaded,variance_reduction}
    project_Î¸ = ProjectTo(Î¸)

    (; nb_samples) = F
    xs = presamples(F, Î¸...)
    ys = samples_from_presamples(F, xs; kwargs...)
    y = tmean_or_mean(F, ys)

    _dist_logdensity_grad_partial(x) = dist_logdensity_grad(rc, F, x, Î¸...)
    gs = tmap_or_map(F, _dist_logdensity_grad_partial, xs)

    ys_with_baseline = if (variance_reduction && nb_samples > 1)
        tmap_or_map(F, yi -> yi .- y, ys)
    else
        ys
    end
    K = nb_samples - (variance_reduction && nb_samples > 1)

    function pullback_Reinforce(dy_thunked)
        dy = unthunk(dy_thunked)
        dF = @not_implemented(
            "The fields of the `Reinforce` object are considered constant."
        )
        _single_sample_pullback(g, y) = g .* dot(y, dy)
        dÎ¸ =
            tmapreduce_or_mapreduce(F, _single_sample_pullback, .+, gs, ys_with_baseline) ./
            K
        dÎ¸_proj = project_Î¸(dÎ¸)
        return (dF, dÎ¸_proj...)
    end

    return y, pullback_Reinforce
end
