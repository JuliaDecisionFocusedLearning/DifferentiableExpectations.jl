"""
    Reinforce{threaded} <: DifferentiableExpectation{threaded}

Differentiable parametric expectation `F : Î¸ -> ğ”¼[f(X)]` where `X âˆ¼ p(Î¸)` using the REINFORCE (or score function) gradient estimator:
```
âˆ‚F(Î¸) = ğ”¼[f(X) âˆ‡â‚‚logp(X,Î¸)áµ€]
```

# Example

```jldoctest
using DifferentiableExpectations, Distributions, Zygote

F = Reinforce(exp, Normal; nb_samples=10^5)
F_true(Î¼, Ïƒ) = mean(LogNormal(Î¼, Ïƒ))

Î¼, Ïƒ = 0.5, 1,0
âˆ‡F, âˆ‡F_true = gradient(F, Î¼, Ïƒ), gradient(F_true, Î¼, Ïƒ)
isapprox(collect(âˆ‡F), collect(âˆ‡F_true); rtol=1e-1)

# output

true
```

# Constructor

    Reinforce(
        f,
        dist_constructor,
        dist_gradlogpdf=nothing;
        rng=Random.default_rng(),
        nb_samples=1,
        threaded=false
    )

# Fields

$(TYPEDFIELDS)

# See also

- [`DifferentiableExpectation`](@ref)
"""
struct Reinforce{threaded,F,D,G,R<:AbstractRNG} <: DifferentiableExpectation{threaded}
    f::F
    dist_constructor::D
    dist_logdensity_grad::G
    rng::R
    nb_samples::Int
end

function Base.show(io::IO, rep::Reinforce{threaded}) where {threaded}
    (; f, dist_constructor, dist_logdensity_grad, rng, nb_samples) = rep
    return print(
        io,
        "Reinforce{$threaded}($f, $dist_constructor, $dist_logdensity_grad, $rng, $nb_samples)",
    )
end

function Reinforce(
    f::F,
    dist_constructor::D,
    dist_logdensity_grad::G=nothing;
    rng::R=default_rng(),
    nb_samples=1,
    threaded=false,
) where {F,D,G,R}
    return Reinforce{threaded,F,D,G,R}(
        f, dist_constructor, dist_logdensity_grad, rng, nb_samples
    )
end

function dist_logdensity_grad(
    rc::RuleConfig, F::Reinforce{threaded}, x, Î¸...
) where {threaded}
    (; dist_constructor, dist_logdensity_grad) = F
    if !isnothing(dist_logdensity_grad)
        dÎ¸ = dist_logdensity_grad(Î¸...)
    else
        # TODO: add Distributions.gradlogpdf
        _logdensity_partial(_Î¸...) = logdensityof(dist_constructor(_Î¸...), x)
        l, pullback = rrule_via_ad(rc, _logdensity_partial, Î¸...)
        dÎ¸ = Base.tail(pullback(one(l)))
    end
    return dÎ¸
end

function logdensity_grads_from_presamples(
    rc::RuleConfig,
    F::DifferentiableExpectation{threaded},
    xs::AbstractVector,
    Î¸...;
    kwargs...,
) where {threaded}
    _dist_logdensity_grad_partial(x) = dist_logdensity_grad(rc, F, x, Î¸...)
    if threaded
        return tmap(_dist_logdensity_grad_partial, xs)
    else
        return map(_dist_logdensity_grad_partial, xs)
    end
end

function logdensity_grads_from_presamples(
    rc::RuleConfig,
    F::DifferentiableExpectation{threaded},
    xs::AbstractMatrix,
    Î¸...;
    kwargs...,
) where {threaded}
    _dist_logdensity_grad_partial(x) = dist_logdensity_grad(rc, F, x, Î¸...)
    if threaded
        return tmap(_dist_logdensity_grad_partial, eachcol(xs))
    else
        return map(_dist_logdensity_grad_partial, eachcol(xs))
    end
end

function ChainRulesCore.rrule(
    rc::RuleConfig, F::Reinforce{threaded}, Î¸...; kwargs...
) where {threaded}
    project_Î¸ = ProjectTo(Î¸)

    (; nb_samples) = F
    xs = presamples(F, Î¸...)
    ys = samples_from_presamples(F, xs; kwargs...)

    gs = logdensity_grads_from_presamples(rc, F, xs, Î¸...)

    function pullback_Reinforce(dy_thunked)
        dy = unthunk(dy_thunked)
        dF = @not_implemented(
            "The fields of the `Reinforce` object are considered constant."
        )
        _single_sample_pullback(g, y) = g .* dot(y, dy)
        dÎ¸ = if threaded
            tmapreduce(_single_sample_pullback, .+, gs, ys) ./ nb_samples
        else
            mapreduce(_single_sample_pullback, .+, gs, ys) ./ nb_samples
        end
        dÎ¸_proj = project_Î¸(dÎ¸)
        return (dF, dÎ¸_proj...)
    end

    y = threaded ? tmean(ys) : mean(ys)
    return y, pullback_Reinforce
end
