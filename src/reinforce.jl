"""
    Reinforce{threaded} <: DifferentiableExpectation{threaded}

Differentiable parametric expectation `F : Î¸ -> ğ”¼[f(X)]` where `X âˆ¼ p(Î¸)` using the REINFORCE (or score function) gradient estimator:
```
âˆ‚F(Î¸) = ğ”¼[f(X) âˆ‡â‚‚logp(X,Î¸)áµ€]
```

# Example

```jldoctest
using DifferentiableExpectations, Distributions, Zygote

E = Reinforce(exp, Normal; nb_samples=10^5)
E_true(Î¼, Ïƒ) = mean(LogNormal(Î¼, Ïƒ))

Î¼, Ïƒ = 0.5, 1,0
âˆ‡E, âˆ‡E_true = gradient(F, Î¼, Ïƒ), gradient(E_true, Î¼, Ïƒ)
isapprox(collect(âˆ‡E), collect(âˆ‡E_true); rtol=1e-1)

# output

true
```

# Constructor

    Reinforce(
        f,
        dist_constructor,
        dist_logdensity_grad=nothing;
        rng=Random.default_rng(),
        nb_samples=1,
        threaded=false,
        seed=nothing
    )

# Fields

$(TYPEDFIELDS)

# See also

- [`DifferentiableExpectation`](@ref)
"""
struct Reinforce{t,variance_reduction,F,D,G,R<:AbstractRNG,S<:Union{Int,Nothing}} <:
       DifferentiableExpectation{t}
    "function applied inside the expectation"
    f::F
    "constructor of the probability distribution `(Î¸...) -> p(Î¸)`"
    dist_constructor::D
    "either `nothing` or a parameter gradient callable `(x, Î¸...) -> âˆ‡â‚‚logp(x, Î¸)`"
    dist_logdensity_grad::G
    "random number generator"
    rng::R
    "number of Monte-Carlo samples"
    nb_samples::Int
    "seed for the random number generator, reset before each call. Set to `nothing` for no seeding."
    seed::S
end

function Reinforce(
    f::F,
    dist_constructor::D,
    dist_logdensity_grad::G=nothing;
    rng::R=default_rng(),
    nb_samples=1,
    threaded=false,
    variance_reduction=true,
    seed::S=nothing,
) where {F,D,G,R,S}
    return Reinforce{threaded,variance_reduction,F,D,G,R,S}(
        f, dist_constructor, dist_logdensity_grad, rng, nb_samples, seed
    )
end

function dist_logdensity_grad(rc::RuleConfig, E::Reinforce, x, Î¸...)
    (; dist_constructor, dist_logdensity_grad) = E
    if !isnothing(dist_logdensity_grad)
        dÎ¸ = dist_logdensity_grad(x, Î¸...)
    else
        _logdensity_partial(_Î¸...) = logdensityof(dist_constructor(_Î¸...), x)
        l, pullback = rrule_via_ad(rc, _logdensity_partial, Î¸...)
        dÎ¸ = Base.tail(pullback(one(l)))
    end
    return dÎ¸
end

function ChainRulesCore.rrule(
    rc::RuleConfig, E::Reinforce{t,variance_reduction}, Î¸...; kwargs...
) where {t,variance_reduction}
    project_Î¸ = ProjectTo(Î¸)

    (; f, nb_samples) = E
    xdist = empirical_predistribution(E, Î¸...)
    xs = atoms(xdist)
    fk = FixKwargs(f, kwargs)
    ydist = map(fk, xdist)
    ys = atoms(ydist)
    y = mean(ydist)

    _dist_logdensity_grad_partial(x) = dist_logdensity_grad(rc, E, x, Î¸...)
    gs = mymap(is_threaded(E), _dist_logdensity_grad_partial, xs)

    ys_with_baseline = if (variance_reduction && nb_samples > 1)
        mymap(is_threaded(E), yi -> yi .- y, ys)
    else
        ys
    end
    K = nb_samples - (variance_reduction && nb_samples > 1)

    function pullback_Reinforce(dy_thunked)
        dy = unthunk(dy_thunked)
        dF = @not_implemented(
            "The fields of the `Reinforce` object are considered constant."
        )
        _single_sample_pullback(g, y) = g .* dot(y, dy)
        dÎ¸ =
            mymapreduce(
                is_threaded(E), _single_sample_pullback, .+, gs, ys_with_baseline
            ) ./ K
        dÎ¸_proj = project_Î¸(dÎ¸)
        return (dF, dÎ¸_proj...)
    end

    return y, pullback_Reinforce
end
